# Select the necessary columns in PySpark
full_val_data_key_spark = full_val_data_key.select(cols)
preds_val_full_spark = preds_val_full.select("pred_lis")  # Select only necessary columns from preds_val_full
full_val_data_feature_spark = full_val_data_feature.select("zip54_cd")

# Concatenate DataFrames in PySpark
full_duns_pred_val_spark = (
    full_val_data_key_spark
    .join(preds_val_full_spark, how="inner")  # Specify join type as needed
    .join(full_val_data_feature_spark, how="inner")
)

# Convert to Pandas
full_duns_pred_val = full_duns_pred_val_spark.toPandas()

# Rename columns if necessary (only if they don't already match)
full_duns_pred_val.columns = ['rpt_mth', 'duns_loc_num', 'zip5_cd', 'zip4_cd', 
                              'lis_target_end_mth', 'lis_job_run', 'naics_cd', 
                              'actual_cleu_ga', 'pred_lis', 'zip54_cd']
