# Set chunk size
chunk_size = 500_000

# Initialize an empty list to hold results
predictions = []

# Read and predict in chunks
for start in range(0, len(data), chunk_size):
    chunk = data[start:start + chunk_size]
    chunk_predictions = model.predict(chunk[feature_columns])
    
    # Append predictions to the list
    predictions.extend(chunk_predictions)

# Convert predictions to a DataFrame if needed
predictions_df = pd.DataFrame(predictions, columns=["prediction"])
