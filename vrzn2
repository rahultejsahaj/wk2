from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler
from pyspark.ml import Pipeline
from catboost import CatBoostRegressor
import numpy as np
import pandas as pd
import time

# Create a Spark session
spark = SparkSession.builder \
    .appName("CatBoost Example") \
    .getOrCreate()

# Load your data into DataFrames
# Assuming train_data_feature, val_data_feature, full_val_data_feature, and train_data_target are available

# Define columns
all_features_cols = [
    'emp_tot_num', 'naics_cd1', 'wireless_bill_tot_amt', 'mob_emp_tot_loc_num', 
    'mob_broadband_bill_tot_amt', 'pq_cleu_ga_1mth', 'pq_nl_ga_1mth', 
    'pq_base_ga_1mth', 'pq_phone_ga_1mth', 'pq_tablet_ga_1mth', 
    'pq_mbb_ga_1mth', 'pq_lis_1mth', 'pq_tablet_lis_1mth', 'pq_mbb_lis_1mth',
    'pq_smartphone_lis_1mth', 'base_ga_previous_1mth', 'zip5_cleu_sum', 
    'zip5_nl_ga_sum', 'zip5_base_ga_sum', 'zip5_lis_sum', 'zip5_cd', 
    'zip4_cd', 'zip54_cleu_sum', 'zip54_nl_ga_sum', 'zip54_base_ga_sum', 
    'zip54_lis_sum', 'pq_cleu_ga_3mth', 'pq_nl_ga_3mth', 'pq_base_ga_3mth', 
    'pq_phone_ga_3mth', 'pq_tablet_ga_3mth', 'pq_mbb_ga_3mth', 'pq_lis_3mth', 
    'pq_tablet_lis_3mth', 'pq_mbb_lis_3mth', 'pq_smartphone_lis_3mth', 
    'chgd_wireless_provider_index', 'city_nm', 'base_yr_emp', 
    'base_yr_sls', 'bus_nm', 'ceo_title', 'pct_growth_emp', 
    'pct_growth_sls', 'population_cd', 'residence_cd', 'segmt_cd', 
    'sls_cd', 'sls_tot', 'subsidiary_cd', 'st_cnty_cd', 'territory_cd', 
    'trend_yr_emp', 'trend_yr_sls', 'wireless_data_apps_index', 
    'wireless_push_to_talk_index', 'wireless_voice_apps_index', 
    'business_age', 'ratio_cleu_subs_p_1mth', 'ratio_cleu_subs_p_3mth', 
    'total_employee_count', 'annual_revenue', 'vz_connect', 
    'intent_mobility_10', 'intent_wls_bi_10', 'intent_networks_10', 
    'wireless_12_month_spend', 'wireline_12_month_spend', 
    'connect_12_month_spend', 'fg_customer_loc', 'fg_pro_10', 
    'ltebi_lq_10', 'exist_ltebi_customer_10', 'ltebi_wfh_10', 
    'wls_promo_10', 'ports_lines', 'linkedin_jobs_posted', 
    'linkedin_hiring_10', 'wls_wallet_share', 'wln_wallet_share', 
    'fios_loc', 'covered_prc', 'nfs_voice_perc', 'nfs_data_perc', 
    'future_5g_availability_10', 'zip5_duns_cnt', 'zip5_vz_cust_cnt', 
    'zip5_prospect_cnt', 'zip54_duns_cnt', 'zip54_vz_cust_cnt', 
    'zip54_prospect_cnt', 'wln_rel', 'con_rel', 'has_vz_rel', 
    'wln_ser_loc', 'vz_hq_rel', 'zip5_qes_score_sum', 
    'zip54_qes_score_sum', 'qes_score'
]

num_f = [
    'emp_tot_num', 'wireless_bill_tot_amt', 'mob_emp_tot_loc_num', 
    'mob_broadband_bill_tot_amt', 'pq_cleu_ga_1mth', 'pq_nl_ga_1mth', 
    'pq_base_ga_1mth', 'pq_phone_ga_1mth', 'pq_tablet_ga_1mth', 
    'pq_mbb_ga_1mth', 'pq_lis_1mth', 'pq_tablet_lis_1mth', 
    'pq_mbb_lis_1mth', 'pq_smartphone_lis_1mth', 'base_ga_previous_1mth', 
    'zip5_cleu_sum', 'zip5_nl_ga_sum', 'zip5_base_ga_sum', 
    'zip5_lis_sum', 'zip54_cleu_sum', 'zip54_nl_ga_sum', 
    'zip54_base_ga_sum', 'zip54_lis_sum', 'pq_cleu_ga_3mth', 
    'pq_nl_ga_3mth', 'pq_base_ga_3mth', 'pq_phone_ga_3mth', 
    'pq_tablet_ga_3mth', 'pq_mbb_ga_3mth', 'pq_lis_3mth', 
    'pq_tablet_lis_3mth', 'pq_mbb_lis_3mth', 'pq_smartphone_lis_3mth', 
    'chgd_wireless_provider_index', 'base_yr_emp', 'base_yr_sls', 
    'pct_growth_emp', 'pct_growth_sls', 'sls_tot', 'trend_yr_emp', 
    'trend_yr_sls', 'wireless_data_apps_index', 'wireless_push_to_talk_index', 
    'wireless_voice_apps_index', 'business_age', 'ratio_cleu_subs_p_1mth', 
    'ratio_cleu_subs_p_3mth', 'total_employee_count', 'annual_revenue', 
    'intent_mobility_10', 'intent_wls_bi_10', 'intent_networks_10', 
    'wireless_12_month_spend', 'wireline_12_month_spend', 
    'connect_12_month_spend', 'fg_customer_loc', 'fg_pro_10', 
    'ltebi_lq_10', 'exist_ltebi_customer_10', 'ltebi_wfh_10', 
    'wls_promo_10', 'ports_lines', 'linkedin_jobs_posted', 
    'linkedin_hiring_10', 'wls_wallet_share', 'wln_wallet_share', 
    'fios_loc', 'covered_prc', 'nfs_voice_perc', 'nfs_data_perc', 
    'future_5g_availability_10', 'zip5_duns_cnt', 'zip5_vz_cust_cnt', 
    'zip5_prospect_cnt', 'zip54_duns_cnt', 'zip54_vz_cust_cnt', 
    'zip54_prospect_cnt', 'wln_rel', 'con_rel', 'has_vz_rel', 
    'wln_ser_loc', 'vz_hq_rel', 'zip5_qes_score_sum', 
    'zip54_qes_score_sum', 'qes_score'
]

cat_features = [
    'naics_cd1', 'zip5_cd', 'zip4_cd', 'zip54_cd', 'city_nm', 
    'ceo_title', 'population_cd', 'residence_cd', 'segmt_cd', 
    'sls_cd', 'subsidiary_cd', 'st_cnty_cd', 'territory_cd', 
    'marketable_ind', 'vz_connect'
]

# Function to scale features
def get_feature_scaler(df, all_features_cols, num_f, cat_features):
    assembler = VectorAssembler(inputCols=num_f, outputCol='features')
    scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withMean=True, withStd=True)

    pipeline = Pipeline(stages=[assembler, scaler])
    pipeline_model = pipeline.fit(df)
    scaled_df = pipeline_model.transform(df)

    # Select scaled features and categorical features
    final_df = scaled_df.select('scaled_features', *cat_features)
    return final_df

# Scale the training, validation, and full validation data
scaler_train = get_feature_scaler(train_data_feature, all_features_cols, num_f, cat_features)
scaler_val = get_feature_scaler(val_data_feature, all_features_cols, num_f, cat_features)
scaler_full_val = get_feature_scaler(full_val_data_feature, all_features_cols, num_f, cat_features)
